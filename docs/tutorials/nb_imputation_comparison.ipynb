{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation Comparison\n",
    "\n",
    "[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ing-bank/probatus/blob/master/docs/tutorials/nb_imputation_comparison.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains how the `ImputationSelector` class works in `probatus`. With `ImputationSelector` you can compare multiple imputation strategies\n",
    "and choose a strategy which works the best for a given model and a dataset.\n",
    "Currently `ImputationSelector` supports any scikit learn compatible imputation strategy. For categorical variables the missing values are replaced by `missing` token and `OneHotEncoder` is applied. The user supplied imputation strategies are applied to numerical columns only. \n",
    "Support for user supplied imputation strategies for categorical columns can be added in the future releases.\n",
    "\n",
    "Let us create some data on which we want to apply the various imputation strategies.We will create a dataset with both numerical and categorical variables.First let us import the class and other required classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_row', 500)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probatus.missing_values.imputation import ImputationSelector\n",
    "from probatus.utils.missing_helpers import generate_MCAR,get_data\n",
    "import pandas as pd \n",
    "import lightgbm as lgb \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import KNNImputer,SimpleImputer,IterativeImputer\n",
    "from feature_engine.imputation import RandomSampleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_data(n_samples=1000,n_numerical=10,n_category=5)\n",
    "print(f\"Shape of X,y : {X.shape},{y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add missing values to the dataset. `generate_MCAR` method randomly adds missing values to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing = generate_MCAR(X,missing=0.2)\n",
    "X_missing.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary with all the strategies to compare. Also, create a classifier that you want to use to evaluate various strategies.\n",
    "If the model supports handling of missing features by default then the model performance on an unimputed dataset is calculated.\n",
    "The model performance against the unimputed dataset can be found in `Model Imputation` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = {\n",
    "    'KNN' : KNNImputer(n_neighbors=3),\n",
    "    'Simple Median Imputer' : SimpleImputer(strategy='median',add_indicator=True),\n",
    "    'Iterative Imputer'  : IterativeImputer(add_indicator=True,n_nearest_features=5,\n",
    "    sample_posterior=True)\n",
    "    }\n",
    "clf = lgb.LGBMClassifier()\n",
    "cmp = ImputationSelector(clf=clf,strategies=strategies,cv=5,random_state=45)\n",
    "cmp.fit_compute(X_missing,y)\n",
    "cmp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However if the model does not support missing values by default e.g LogisticRegression , results for only the inputation strategies are calculated. This can be indicated by setting the `model_na_support` parameter to `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = {\n",
    "    'KNN' : KNNImputer(n_neighbors=3),\n",
    "    'Simple Median Imputer' : SimpleImputer(strategy='median',add_indicator=True),\n",
    "    'Simple Mean Imputer' : SimpleImputer(strategy='mean',add_indicator=False),\n",
    "    'Iterative Imputer'  : IterativeImputer(add_indicator=True,n_nearest_features=5,\n",
    "    sample_posterior=True)\n",
    "    }\n",
    "clf = LogisticRegression()\n",
    "cmp = ImputationSelector(clf=clf,strategies=strategies,cv=10,model_na_support=False)\n",
    "cmp.fit_compute(X_missing,y)\n",
    "cmp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass a sklearn pipline instead of a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "steps = [('scaler', StandardScaler()), ('LR', LogisticRegression())]\n",
    "clf = Pipeline(steps)\n",
    "cmp = ImputationSelector(clf=clf,strategies=strategies,cv=10,model_na_support=False)\n",
    "cmp.fit_compute(X_missing,y)\n",
    "cmp.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn Compatible Imputers. \n",
    "\n",
    "You can also use any other scikit-learn compatible imputer as an imputing strategy.\n",
    "eg. [feature engine](https://feature-engine.readthedocs.io/en/latest/index.html) library provides a host of other imputing stratgies as well. You can pass them for comparision. Let us try the `RandomSampleImputer`. You can read more about it [here](https://feature-engine.readthedocs.io/en/latest/imputation/RandomSampleImputer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = {\n",
    "    'KNN' : KNNImputer(n_neighbors=3),\n",
    "    'Simple Median Imputer' : SimpleImputer(strategy='median',add_indicator=True),\n",
    "    'Iterative Imputer'  : IterativeImputer(add_indicator=True,n_nearest_features=5,\n",
    "    sample_posterior=True),\n",
    "    'Random Imputation' : RandomSampleImputer()\n",
    "    }\n",
    "clf = lgb.LGBMClassifier()\n",
    "cmp = ImputationSelector(clf=clf,strategies=strategies,cv=10)\n",
    "cmp.fit_compute(X_missing,y)\n",
    "cmp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('probatus': conda)",
   "language": "python",
   "name": "python361264bitprobatusconda74d285a941224501ac9ae4f70b7fd0f5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}