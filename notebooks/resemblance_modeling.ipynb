{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resemblance\n",
    "\n",
    "Resemblance models try to measure how different two samples are from a multivariate perspective.<br>\n",
    "\n",
    "It works as follows:\n",
    "- takes in input two datasets, X1, and X2\n",
    "- it labels them with 0 and 1\n",
    "- builds a model that will try to predict to which sample does an observation belong.\n",
    "- when this model has an AUC = 0.5, it means that the samples are not distingushable.\n",
    "\n",
    "In the present case, an AUC close to 50% is the expected result because it means that the features are uninformative for the 'classification' of the instances into the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T08:58:34.812113Z",
     "start_time": "2019-08-26T08:58:33.945699Z"
    }
   },
   "outputs": [],
   "source": [
    "from probatus.datasets import lending_club\n",
    "from sklearn.model_selection import train_test_split\n",
    "from probatus.samples import ResemblanceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the lending club dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T08:58:34.857026Z",
     "start_time": "2019-08-26T08:58:34.813863Z"
    }
   },
   "outputs": [],
   "source": [
    "credit_df ,X_train,X_test,y_train, y_test =  lending_club()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model on two samples, in this case we want to compare how similar are train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T08:58:35.021482Z",
     "start_time": "2019-08-26T08:58:34.922868Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fb24xi/miniconda3/envs/probapy/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResemblanceModel\n",
       "\tUnderlying model type: RandomForestClassifier\n",
       "The model is able to distinguish the samples with an AUC of 0.498"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm = ResemblanceModel().fit(X_train, X_test)\n",
    "rm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "This is the expected results as the model is not able to categorize an instance based on the features. This is a first indication the train and test set are similar in feature distribution.\n",
    "If this is not the case, looking at the importance may help us identifying the feature(s) that cause the issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check which features seem to have a higher importance in predicting to which sample does the model belong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T08:58:35.026981Z",
     "start_time": "2019-08-26T08:58:35.023075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt          0.144486\n",
       "funded_amnt        0.145201\n",
       "term               0.015892\n",
       "int_rate           0.200380\n",
       "annual_inc         0.220503\n",
       "fico_range_low     0.108164\n",
       "fico_range_high    0.102589\n",
       "long_emp           0.028907\n",
       "credit_grade_A     0.004518\n",
       "credit_grade_B     0.006247\n",
       "credit_grade_C     0.009524\n",
       "credit_grade_D     0.006349\n",
       "credit_grade_E     0.004318\n",
       "credit_grade_F     0.002342\n",
       "credit_grade_G     0.000579\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProbaPy",
   "language": "python",
   "name": "probapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
